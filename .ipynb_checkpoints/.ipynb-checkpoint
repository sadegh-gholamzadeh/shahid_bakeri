{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --keyword KEYWORD [--count COUNT]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --keyword\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadegh\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import base64\n",
    "import argparse\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_image_from_base64(codec):\n",
    "    \"\"\" convert base64 to image \"\"\"\n",
    "    base64_data = re.sub('^data:image/.+;base64,', '', codec)\n",
    "    img = Image.open(BytesIO(base64.b64decode(base64_data)))\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "class Crawler:\n",
    "    \"\"\"\n",
    "    Google Web Image Crawler\n",
    "    \"\"\"\n",
    "    def __init__(self, keyword, count):\n",
    "        self.keyword = str(keyword)  # image keyword for searching\n",
    "        self.count = count  # image count\n",
    "        self.dirPath = \"\"  # image stored directory\n",
    "\n",
    "    def create_new_directory(self):\n",
    "        \"\"\"\n",
    "        Create directory for download if it is not exist\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.cwd = os.getcwd()\n",
    "        self.dirPath = os.path.join(self.cwd, self.keyword)\n",
    "\n",
    "        if not os.path.exists(self.dirPath):\n",
    "            os.mkdir(self.dirPath)\n",
    "\n",
    "    def create_url(self):\n",
    "        \"\"\"\n",
    "        Create the url path\n",
    "        :return: url for searching\n",
    "        \"\"\"\n",
    "        url = 'https://www.google.com/search?q=' + self.keyword + '&source=lnms&tbm=isch'\n",
    "        return url\n",
    "\n",
    "    def search_url(self, url):\n",
    "        \"\"\"\n",
    "        Search from chrome browser\n",
    "        :param url: search url\n",
    "        :return: webdriver\n",
    "        \"\"\"\n",
    "        # ========== headless driver options ========== #\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument('headless')\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"lang=ko_KR\")\n",
    "        chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\")\n",
    "        # ... etc\n",
    "        # ============================================= #\n",
    "\n",
    "        # if you don't want headless driver, remove chrome_option argument\n",
    "        browser = webdriver.Chrome(os.path.join(self.cwd,'chromedriver'), chrome_options=chrome_options)\n",
    "        browser.get(url)\n",
    "        print(url)\n",
    "\n",
    "        # scroll by 10000px\n",
    "        pk = self.count // 100 - 1\n",
    "        scroll = 1 if pk == 0 else 250 * pk\n",
    "        for _ in range(scroll):\n",
    "            browser.execute_script('window.scrollBy(0, 10000)')\n",
    "\n",
    "        return browser\n",
    "\n",
    "    def download_image(self, browser):\n",
    "        \"\"\"\n",
    "        Download the image\n",
    "        :param browser: google webdriver\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        elements = browser.find_elements_by_xpath('//img[contains(@class,\"rg_i\")]')\n",
    "        element_size = len(elements)  # used for progress status\n",
    "\n",
    "        for idx in tqdm(range(element_size), bar_format='{l_bar}{bar:20}{r_bar}{bar:-10b}'):\n",
    "            save_path = self.dirPath + '/' + str(idx) + '.jpg'\n",
    "            img_src = elements[idx].get_attribute('src')\n",
    "            if img_src is None:\n",
    "                img_src = elements[idx].get_attribute('data-src')\n",
    "\n",
    "            if str(img_src).startswith('data:image'):\n",
    "                img = get_image_from_base64(img_src)\n",
    "                img.save(save_path, 'JPEG')\n",
    "            else:\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(img_src, save_path)\n",
    "                except Exception as e:\n",
    "                    print('exception: ', idx, e)\n",
    "\n",
    "        browser.close()  # close the browser\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        main routines\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.create_new_directory()           # 1. create the directory\n",
    "        url = self.create_url()              # 2. create the path\n",
    "        browser = self.search_url(url)       # 3. search image\n",
    "        self.download_image(browser)         # 4. download image\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='구글 이미지 크롤러 v2')\n",
    "    parser.add_argument('--keyword', required=True, type=str, help='검색할 이미지 키워드')\n",
    "    parser.add_argument('--count', required=False, type=int, default=100, help='이미지 개수 100 단위로')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    newCrawler = Crawler(args.keyword, args.count)  # create new crawler\n",
    "    newCrawler.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-4e652b21e7cb>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-4e652b21e7cb>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python crawler.py --keyword 'Mehdi Bakeri' --count '100'\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python crawler.py --keyword 'Mehdi Bakeri' --count '100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-fe04cee02473>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-fe04cee02473>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python crawler.py --keyword <Mehdi Bakeri> --count <150>\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python crawler.py --keyword <Mehdi Bakeri> --count <100>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
